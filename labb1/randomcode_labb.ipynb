{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardio_counts = df_cardio[\"CVD\"].value_counts()\n",
    "print(f\"Distribution of Cardiovasculuar Disease:\\n{cardio_counts}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotta en countplot för att se hur många som är sjuka och friska.\n",
    "sns.countplot(x=\"CVD\", data=df_cardio, palette=\"Set2\")\n",
    "plt.title(\"Cardiovascular Disease (CVD) Distribution\")\n",
    "plt.xlabel(\"CVD\")\n",
    "plt.ylabel(\"Observations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Räkna antalet observationer i varje kategori för kolesterol och sertera dem efter index.\n",
    "cholesterol_counts = df_cardio[\"cholesterol\"].value_counts().sort_index()\n",
    "\n",
    "# Beräkna andelen (i procent) för varje kategori\n",
    "cholesterol_percentages = round((cholesterol_counts / len(df) * 100), 1)\n",
    "print(f\"Cholesterol per Categhory in (%): \\n{cholesterol_percentages}\")\n",
    "\n",
    "# Skapa etiketter för dessa kategorier: 1 = Normalt, 2 = Över normalt, 3 = Långt över normalt\n",
    "labels = [\"Normal \", \"Above normal\", \"Way above normal\"]\n",
    "\n",
    "# Rita tårtdiagram\n",
    "# Kod-bit från: https://matplotlib.org/stable/gallery/pie_and_polar_charts/pie_features.html\n",
    "plt.pie(cholesterol_counts, labels=labels, autopct='%1.1f%%', startangle=90, colors=[\"#66c2a5\", \"#8da0cb\", \"#fc8d62\",])\n",
    "plt.axis('equal')\n",
    "plt.title('Cholesterol per Category')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skapa en countplot för CVD på kön \n",
    "sns.countplot(x=\"gender_label\", data=df_cardio, hue=\"CVD\", palette=\"Set2\")\n",
    "plt.title(\"Share Cardiovasculuar Disease based on Gender\")\n",
    "plt.xlabel(\"Gender\")\n",
    "plt.ylabel(\"Observations\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "\n",
    "# Sätt storleken på plottear \n",
    "rcParams[\"figure.figsize\"] = 10, 6\n",
    "\n",
    "\n",
    "# Ändra värdena i kolumnen cardio till Yes och No\n",
    "df_cardio[\"CVD\"] = df_cardio[\"cardio\"].map({1: 'Yes', 0: 'No'}) # kodhjälp\" prompt\"XX\"\n",
    "\n",
    "# Plotta en countplot för att se hur många som har hjärt- och kärlsjukdomar\n",
    "rcParams[\"figure.figsize\"] = 10, 6\n",
    "df_cardio[\"age_years\"] = (df_cardio[\"age\"] / 365).round().astype(\"int\")\n",
    "sns.countplot(x=\"age_years\", hue=\"CVD\", data=df_cardio, palette=\"Set2\")\n",
    "plt.title(\"Distribution of Cardiovasculur Disease (CVD) by Age\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Observations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='cardio', data=df, palette=\"Set2\", ax=ax[0, 0])\n",
    "ax[0, 0].set_title(\"Fördelning av hjärt-kärlsjukdom\")\n",
    "ax[0, 0].set_xlabel('Hjärt-kärlsjukdom')\n",
    "ax[0, 0].set_ylabel('Antal observationer')\n",
    "ax[0, 0].set_xticks([0, 0])\n",
    "ax[0, 0].set_xticklabels(['Negativ', 'Positiv'])\n",
    "\n",
    "df_sex = sns.countplot(x=\"gender\", hue= \"cardio\", data=df, palette=\"Set2\", ax=ax[2, 1])\n",
    "ax[2, 1].set_title(\"Könsfördelning och hjärt-kärlsjukdom\")\n",
    "ax[2, 1].set_xlabel(\"Kön\")\n",
    "ax[2, 1].set_ylabel(\"Antal observationer\")\n",
    "ax[2, 1].set_xticklabels([\"Kvinna\", \"Man\"])  \n",
    "\n",
    "ax[1, 0].pie(cholesterol_counts, labels=[\"Normal\", \"Över normalt\", \"Långt över normalt\"], autopct=\"%1.1f%%\")\n",
    "ax[1, 0].set_title(\"Kolesterolvärde\")\n",
    "# Sätter nya etiketter direkt\n",
    "\n",
    "#Prompt om jag även vill ändra hue=\"cardio\" så den visar titel: \"Hjärt och Kärlsjuk\" och istället för att visa 1 och 0 så visa Positiv och Negativ? \n",
    "# Hämta nuvarande legend och ändra dess etiketter och titel \n",
    "handles, labels = ax[2, 1].get_legend_handles_labels()\n",
    "# Vi antar att labels är ['0', '1'], mappa om dem:\n",
    "new_labels = ['Negativ' if lbl == '0' else 'Positiv' for lbl in labels]\n",
    "ax[2, 1].legend(handles=handles, labels=new_labels, title=\"Hjärt och Kärlsjuk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cardio.columns\n",
    "df_cardio[['ap_hi', 'ap_lo']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"ap_lo\", data=df_cardio)\n",
    "plt.title(\"Diastolic Blood Pressure Distribution\") \n",
    "plt.xlabel(\"Diastolic Blood Pressure\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Räkna antalet negativa värden i 'ap_hi'\n",
    "negative_ap_hi_count = (df_cardio['ap_hi'] < 0).sum()\n",
    "print(\"Antal negativa värden i ap_hi:\", negative_ap_hi_count)\n",
    "\n",
    "# Räkna antalet negativa värden i 'ap_lo'\n",
    "negative_ap_lo_count = (df_cardio['ap_lo'] < 0).sum()\n",
    "print(\"Antal negativa värden i ap_lo:\", negative_ap_lo_count)\n",
    "\n",
    "# Ta bort negativa värden från df_cardio.\n",
    "df_cardio = df_cardio[(df_cardio['ap_hi'] >= 0) & (df_cardio['ap_lo'] >= 0)]\n",
    "\n",
    "# Kontrollera att negativa värden har tagits bort\n",
    "negative_ap_hi_count = (df_cardio['ap_hi'] < 0).sum()\n",
    "negative_ap_lo_count = (df_cardio['ap_lo'] < 0).sum()\n",
    "print(\"Antal negativa värden i ap_hi efter borttagning:\", negative_ap_hi_count)\n",
    "print(\"Antal negativa värden i ap_lo efter borttagning:\", negative_ap_lo_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skriv anatalet värden där diastoliskt överstiger systoliskt värde. \n",
    "print(\"Diastilic pressure is higher than systolic in {0} cases\".format(df_cardio[df_cardio['ap_lo']> df_cardio['ap_hi']].shape[0]))\n",
    "\n",
    "# Ta bort värden sär diastoliskt > systoliskt\n",
    "df_cardio = df_cardio[df_cardio['ap_lo'] <= df_cardio['ap_hi']]\n",
    "print(\"Antalet diastoliska värden som överstiger sysolsika värden efter borttagning i {0}\".format(df_cardio[df_cardio['ap_lo']> df_cardio['ap_hi']].shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.countplot(\n",
    "    x=\"bp_category\",      # The categorical variable\n",
    "    hue=\"CVD\",         # Split by cardio (0 or 1)\n",
    "    data=df_cardio, \n",
    "    palette=\"magma\", \n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title(\"CVD per Blood Pressure Category\")\n",
    "ax.set_xlabel(\"Blood Pressure Category\")\n",
    "ax.set_ylabel(\"Number of Observations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Count how many rows per (bp_category, cardio)\n",
    "grouped = df_cardio.groupby(['bp_category', 'CVD']).size().reset_index(name='count')\n",
    "\n",
    "# 2. Compute total rows per bp_category to get fraction\n",
    "totals = grouped.groupby('bp_category')['count'].transform('sum')\n",
    "grouped['proportion'] = grouped['count'] / totals\n",
    "\n",
    "# 3. Plot as grouped bar chart of proportions\n",
    "fig, ax = plt.subplots()\n",
    "sns.barplot(\n",
    "    x='bp_category', \n",
    "    y='proportion', \n",
    "    hue='CVD', \n",
    "    data=grouped, \n",
    "    palette='magma', \n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Proportion of Heart Disease per Blood Pressure Category')\n",
    "ax.set_xlabel('Blodtryckskategori')\n",
    "ax.set_ylabel('Andel (proportion)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sjuka i CVD\n",
    "cardio_pos = df_cardio[df_cardio[\"cardio\"] == 1]\n",
    "\n",
    "# skapa en countplot för sjuka i hjärt- och kärlsjukdomar per blodtryckskategori\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=cardio_pos, x=\"bp_category\", palette=\"Set2\")\n",
    "plt.title(\"CVD postive per Blood Pressure Category\")\n",
    "plt.xlabel(\"Blood Pressure Category\")\n",
    "plt.ylabel(\"Number of Observations\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# skapa en countplot per kön sjuka i hjärt- och kärlsjukdomar\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=cardio_pos, x=\"gender_label\", palette=\"Set2\")\n",
    "plt.title(\"CVD positive per gender\")\n",
    "plt.xlabel(\"Gender\")\n",
    "plt.ylabel(\"Number of Observations\")\n",
    "plt.xticks\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exempel: Andelen positiva för varje kolesterolkategori\n",
    "chol_frac = df_cardio.groupby('cholesterol')['cardio'].mean().reset_index()\n",
    "chol_frac.columns = ['cholesterol', 'fraction_positive']\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 24))\n",
    "\n",
    "# Barplot 1: Blodtryckskategorier\n",
    "sns.barplot(x='bp_category', y='fraction_positive', hue='bp_category', data=bp_frac, ax=axes[0], palette='viridis', legend=False)\n",
    "axes[0].set_title('Andel positiva per blodtryckskategori')\n",
    "axes[0].set_xlabel('Blodtryckskategori')\n",
    "axes[0].set_ylabel('Andel positiva')\n",
    "\n",
    "# Barplot 2: BMI-kategorier\n",
    "sns.barplot(x='BMI_cat', y='fraction_positive', hue='BMI_cat', data=bmi_frac, ax=axes[1], palette='magma', legend=False)\n",
    "axes[1].set_title('Andel positiva per BMI-kategori')\n",
    "axes[1].set_xlabel('BMI-kategori')\n",
    "axes[1].set_ylabel('Andel positiva')\n",
    "\n",
    "# Barplot 3: Kolesterol\n",
    "sns.barplot(x='cholesterol', y='fraction_positive', hue='cholesterol', data=chol_frac, ax=axes[2], palette='viridis', legend=False)\n",
    "axes[2].set_title('Andel positiva per kolesterolkategori')\n",
    "axes[2].set_xlabel('Kolesterolkategori')\n",
    "axes[2].set_ylabel('Andel positiva')\n",
    "\n",
    "# Barplot 4: Kön\n",
    "sns.barplot(x=\"gender\", y=\"fraction_positive\", hue=\"gender\", data=sex_frac, ax=axes[3], palette=\"viridis\", legend=False)\n",
    "axes[3].set_title(\"Andel positiva per kön\")\n",
    "axes[3].set_xlabel(\"Kön\")\n",
    "axes[3].set_ylabel(\"Andel positiva\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subplot 1: Countplot\n",
    "sns.countplot(\n",
    "    x=\"bp_category\", \n",
    "    hue=\"CVD\", \n",
    "    data=df_cardio, \n",
    "    palette=\"magma\", \n",
    "    ax=axes[0],\n",
    "    order=order\n",
    ")\n",
    "axes[0].set_title(\"CVD per Blood Pressure Category\")\n",
    "axes[0].set_xlabel(\"Blood Pressure Category\")\n",
    "axes[0].set_ylabel(\"Number of Observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Beräkna korrelationsmatrisen¨\n",
    "corr_matrix = df_cardio.corr(numeric_only=True)  # numeric_only=True för att endast ta med numeriska kolumner\n",
    "\n",
    "# 2. Rita en heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Korrelationsmatris')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def prepare_data(df, target_col=\"cardio\", test_size=0.3, val_size=0.3, random_state=42, verbose=True):\n",
    "    # Separera features och target\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "    \n",
    "    # Första uppdelningen: träning och temporärt testset\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # Andra uppdelningen: validerings- och testset från det temporära setet\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=val_size, random_state=random_state)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Träningsset:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "        print(\"Valideringsset:\", X_val.shape, \"y_val:\", y_val.shape)\n",
    "        print(\"Testset:\", X_test.shape, \"y_test:\", y_test.shape)\n",
    "        \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "# Exempel på användning med verbose=True\n",
    "X_train1, X_val1, X_test1, y_train1, y_val1, y_test1 = prepare_data(df1, verbose=True)\n",
    "X_train2, X_val2, X_test2, y_train2, y_val2, y_test2 = prepare_data(df2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Exempel på användning (kan köras i din notebook)\n",
    "# -------------------------------\n",
    "if __name__ == '__main__':\n",
    "    # Ladda in data\n",
    "    loader = DataLoader(\"/Users/paraugustsson/Machine-learning-AI24-1/cardio_train.csv\")\n",
    "    df = loader.load_data()\n",
    "    \n",
    "    # Rensa och skapa features\n",
    "    cleaner = DataCleaner(df)\n",
    "    df_clean = cleaner.get_clean_data()\n",
    "    \n",
    "    # Visualisera EDA\n",
    "    visualizer = DataVisualizer(df_clean)\n",
    "    visualizer.eda_overview()\n",
    "    visualizer.correlation_heatmap()\n",
    "    \n",
    "    # Förbered data (skapa dataset och dela upp)\n",
    "    preparer = DataPreparer(df_clean)\n",
    "    df1, df2 = preparer.create_datasets()\n",
    "    X_train1, X_val1, X_test1, y_train1, y_val1, y_test1 = preparer.train_val_test_split(df1, target_col=\"cardio\")\n",
    "    X_train2, X_val2, X_test2, y_train2, y_val2, y_test2 = preparer.train_val_test_split(df2, target_col=\"cardio\")\n",
    "    \n",
    "    # Träna enskilda modeller på dataset 1 (exempel)\n",
    "    trainer = ModelTrainer()\n",
    "    param_grid_log = {\n",
    "        \"logreg__C\": [0.01, 0.1, 1, 10],\n",
    "        \"logreg__penalty\": [\"l1\", \"l2\"],\n",
    "        \"logreg__solver\": [\"liblinear\", \"saga\"]\n",
    "    }\n",
    "    best_log = trainer.train_logistic_regression(X_train1, y_train1, param_grid_log)\n",
    "    trainer.evaluate_model(best_log, X_val1, y_val1)\n",
    "    \n",
    "    # Träna Random Forest (exempel)\n",
    "    param_grid_rf = {\n",
    "        \"rf__n_estimators\": [100, 200],\n",
    "        \"rf__max_depth\": [5, 10],\n",
    "        \"rf__min_samples_split\": [2, 5],\n",
    "        \"rf__min_samples_leaf\": [1, 2]\n",
    "    }\n",
    "    best_rf = trainer.train_random_forest(X_train1, y_train1, param_grid_rf)\n",
    "    trainer.evaluate_model(best_rf, X_val1, y_val1)\n",
    "    \n",
    "    # Ensemble: skapa en VotingClassifier med de bästa modellerna\n",
    "    ensemble = EnsembleModeler()\n",
    "    estimators = [('log', best_log), ('rf', best_rf)]\n",
    "    voting_clf = ensemble.create_voting_classifier(estimators, voting='soft')\n",
    "    ensemble.train_voting_classifier(X_train1, y_train1)\n",
    "    ensemble.evaluate_voting_classifier(X_val1, y_val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # skapa voting classifier\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Skapa modeller med hyperparametrar från tidigare\n",
    "best_param_log1 = LogisticRegression(C=1, penalty='l1', solver='saga', max_iter=5000) \n",
    "best_param_log2 = LogisticRegression(C=1, penalty=\"l2\", solver=\"liblinear\", max_iter=5000)\n",
    "best_param_rnd1 = RandomForestClassifier(max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100)\n",
    "best_param_rnd2 = RandomForestClassifier(max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100)\n",
    "best_param_tree1 = DecisionTreeClassifier(max_depth=5, min_samples_leaf=1, min_samples_split=2)\n",
    "best_param_tree2 = DecisionTreeClassifier(max_depth=5, min_samples_leaf=1, min_samples_split=5)\n",
    "best_param_svm1 = SVC(C=1, gamma='scale', kernel='rbf', probability=True)\n",
    "best_param_svm2 = SVC(C=10, gamma='scale', kernel='rbf', probability=True)\n",
    "\n",
    "# Skapa en funktion för voting classifier\n",
    "def model (log, tree, rnd, svm):\n",
    "    vot_clf_soft= VotingClassifier(\n",
    "        estimators=[('log', log), \n",
    "                    ('tree', tree), \n",
    "                    ('rnd', rnd),\n",
    "                    ('svm', svm)],\n",
    "        voting='soft'\n",
    "    )\n",
    "    return vot_clf_soft   \n",
    "\n",
    "# Skapa två voting classifiers beroede på de bästa parametrarna per repsektive dataset\n",
    "vot_clf_soft1 = model(best_param_log1, best_param_tree1, best_param_rnd1, best_param_svm1)\n",
    "vot_clf_soft2 = model(best_param_log2, best_param_tree2, best_param_rnd2, best_param_svm2)\n",
    "\n",
    "# Träna voting classifiers\n",
    "vot_clf_soft1.fit(X_train1, y_train1)\n",
    "vot_clf_soft2.fit(X_train2, y_train2)\n",
    "\n",
    "# Utvärdera på valideringsdata (X_val1, y_val1) under utvecklingsfasen\n",
    "y_pred1 = vot_clf_soft1.predict(X_val1)\n",
    "y_pred2 = vot_clf_soft2.predict(X_val2)\n",
    "\n",
    "print(\"Accuracy för voting classifier 1:\", accuracy_score(y_val1, y_pred1))\n",
    "print(\"Accuracy för voting classifier 2:\", accuracy_score(y_val2, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skapa voting classifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Skapa modeller med hyperparametrar från tidigare\n",
    "best_param_log1 = LogisticRegression(C=1, penalty='l1', solver='saga', max_iter=2500)\n",
    "best_param_log2 = LogisticRegression(C=1, penalty=\"l2\", solver=\"liblinear\", max_iter=2500)\n",
    "best_param_rnd1 = RandomForestClassifier(max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100)\n",
    "best_param_rnd2 = RandomForestClassifier(max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100)\n",
    "best_param_tree1 = DecisionTreeClassifier(max_depth=5, min_samples_leaf=1, min_samples_split=2)\n",
    "best_param_tree2 = DecisionTreeClassifier(max_depth=5, min_samples_leaf=1, min_samples_split=5)\n",
    "best_param_svm1 = SVC(C=1, gamma='scale', kernel='rbf', probability=True)\n",
    "best_param_svm2 = SVC(C=10, gamma='scale', kernel='rbf', probability=True)\n",
    "\n",
    "# Skapa en funktion för voting classifier\n",
    "def model (log, tree, rnd, svm):\n",
    "    voting_clf = VotingClassifier(\n",
    "        estimators=[('log', log), \n",
    "                    ('tree', tree), \n",
    "                    ('rnd', rnd),\n",
    "                    ('svm', svm)],\n",
    "        voting='hard'\n",
    "    )\n",
    "    return voting_clf   \n",
    "\n",
    "# Skapa två voting classifiers\n",
    "voting_clf_1 = model(best_param_log1, best_param_tree1, best_param_rnd1, best_param_svm1)\n",
    "voting_clf2 = model(best_param_log2, best_param_tree2, best_param_rnd2, best_param_svm2)\n",
    "\n",
    "# Träna voting classifiers\n",
    "voting_clf1.fit(X_train1, y_train1)\n",
    "voting_clf2.fit(X_train2, y_train2)\n",
    "\n",
    "# Skriv ut accuracy för voting classifiers\n",
    "print(\"Accuracy för voting classifier 1:\", voting_clf1.score(X_val1, y_val1))\n",
    "print(\"Accuracy för voting classifier 2:\", voting_clf2.score(X_val2, y_val2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_evaluation_scores(self, models: dict, X_val_list, y_val_list, dataset_names): \n",
    "        \"\"\"\n",
    "        Skapar ett stapeldiagram med precision, recall och F1-score för varje modell i varje dataset.\n",
    "\n",
    "        :param models: Dict med modellnamn som nycklar och modeller som värden.\n",
    "        :param X_val_list: Lista med X_val för respektive dataset.\n",
    "        :param y_val_list: Lista med y_val för respektive dataset.\n",
    "        :param dataset_names: Lista med namn för dataset (ex: ['Dataset 1', 'Dataset 2'])\n",
    "        \"\"\"\n",
    "\n",
    "        results = []\n",
    "        for ds_index, (X_val, y_val) in enumerate(zip(X_val_list, y_val_list)):\n",
    "            for name, model in models.items():\n",
    "                y_pred = model.predict(X_val)\n",
    "                precision = precision_score(y_val, y_pred, pos_label=1)\n",
    "                recall = recall_score(y_val, y_pred, pos_label=1)\n",
    "                f1 = f1_score(y_val, y_pred, pos_label=1)\n",
    "                results.append({\n",
    "                    \"Dataset\": dataset_names[ds_index],\n",
    "                    \"Model\": name,\n",
    "                    \"Precision\": precision,\n",
    "                    \"Recall\": recall,\n",
    "                    \"F1 Score\": f1\n",
    "                })\n",
    "\n",
    "        df_results = pd.DataFrame(results)\n",
    "        melted = df_results.melt(id_vars=[\"Dataset\", \"Model\"],\n",
    "                                 value_vars=[\"Precision\", \"Recall\", \"F1 Score\"],\n",
    "                                 var_name=\"Metric\",\n",
    "                                 value_name=\"Score\")\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.barplot(x=\"Model\", y=\"Score\", hue=\"Metric\", data=melted, errorbar=None)\n",
    "        plt.title(\"Modellutvärdering: Precision, Recall och F1-Score\")\n",
    "        plt.ylim(0, 1)\n",
    "        plt.ylabel(\"Score\")\n",
    "        plt.xlabel(\"Modell\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ladd om moduler automatiskt som ändras under utveckling\n",
    "# Kodhjälp ChatGPT, prompt: \"hur kan jag ladda om funktioner som ändras löpande i en py-fil med klasser i som jag använder i jupyter notebok?\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skapa en instans för träning av Logistic Regression-modellen\n",
    "trainer = ModelTrainer() \n",
    "\n",
    "# Definiera modellens hyperparametarar\n",
    "param_grid_lr = {\n",
    "    \"lr__C\": [0.01, 0.1, 1, 10],\n",
    "    \"lr__penalty\": [\"l1\", \"l2\"],\n",
    "    \"lr__solver\": [\"liblinear\", \"saga\"]\n",
    "}\n",
    "\n",
    "# Träna, parametertuna och korsvalidera modellen på båda datasetten och spara den bästa modellen\n",
    "# Dataset 1:\n",
    "best_model1 = trainer.train_logistic_regression(X_train1, y_train1, param_grid_lr)\n",
    "trainer.save_model(best_model1, \"logistic_regression_dataset1.pkl\")\n",
    "# Dataset 2:\n",
    "best_model2 = trainer.train_logistic_regression(X_train2, y_train2, param_grid_lr)\n",
    "trainer.save_model(best_model2, \"logistic_regression_dataset2.pkl\")\n",
    "\n",
    "# Validera modellen på dataset 1 och 2\n",
    "trainer.evaluate_model(best_model1, X_val1, y_val1)\n",
    "trainer.evaluate_model(best_model2, X_val2, y_val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skapa en instans för träning av Random Forest-modellen\n",
    "trainer = ModelTrainer()\n",
    "\n",
    "# Definiera modellens hyperparametarar\n",
    "param_grid_rf = {\n",
    "    \"rf__n_estimators\": [100, 200, 300],\n",
    "    \"rf__max_depth\": [5, 10, 15],\n",
    "    \"rf__min_samples_split\": [2, 5, 10],\n",
    "    \"rf__min_samples_leaf\": [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Träna, parametertuna och korsvalidera modellen på dataset 1 och 2 och spara den bästa modellen\n",
    "# Dataset 1:\n",
    "best_model1 = trainer.train_random_forest(X_train1, y_train1, param_grid_rf)\n",
    "trainer.save_model(best_model1, \"random_forest_dataset1.pkl\")\n",
    "# Dataset 2:\n",
    "best_model2 = trainer.train_random_forest(X_train2, y_train2, param_grid_rf)\n",
    "trainer.save_model(best_model2, \"random_forest_dataset2.pkl\")\n",
    "\n",
    "# Validera modellen på dataset 1 och 2\n",
    "trainer.evaluate_model(best_model1, X_val1, y_val1)\n",
    "trainer.evaluate_model(best_model2, X_val2, y_val2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skapa en instans för träning av SVM-modellen\n",
    "trainer = ModelTrainer()\n",
    "\n",
    "# Definiera modellens hyperparametarar\n",
    "param_grid_svm = {\n",
    "    \"svm__C\": [0.1, 1, 10],\n",
    "    \"svm__kernel\": [\"linear\", \"rbf\"],\n",
    "    \"svm__gamma\": [\"scale\", \"auto\"]\n",
    "}\n",
    "# Träna, parametertuna och korsvalidera modellen på dataset 1 och 2\n",
    "# Dataset 1:\n",
    "best_model1 = trainer.train_svm(X_train1, y_train1, param_grid_svm)\n",
    "trainer.save_model(best_model1, \"svm_dataset1.pkl\")\n",
    "# Dataset 2:\n",
    "best_model2 = trainer.train_svm(X_train2, y_train2, param_grid_svm)\n",
    "trainer.save_model(best_model2, \"svm_dataset2.pkl\")\n",
    "# Validera modellen på dataset 1 och 2\n",
    "trainer.evaluate_model(best_model1, X_val1, y_val1)\n",
    "trainer.evaluate_model(best_model2, X_val2, y_val2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skapa en instans för ensemble-modellering\n",
    "ensemble = EnsembleModeler()\n",
    "\n",
    "# skape en voting classifier för dataset 1 och spara den\n",
    "voting_classifier_hard1 = ensemble.create_voting_classifier(dataset=1, vote_type='hard', X_train=X_train1, y_train=y_train1)\n",
    "ensemble.save_model(voting_classifier_hard1, \"voting_classifier_hard_dataset1.pkl\")\n",
    "# Validera modellen på dataset 1\n",
    "ensemble.evaluate_voting_classifier(X_val1, y_val1)\n",
    "# skape en voting classifier för dataset 2 och spara den\n",
    "voting_classifier_hard2 = ensemble.create_voting_classifier(dataset=2, vote_type='hard', X_train=X_train2, y_train=y_train2)\n",
    "ensemble.save_model(voting_classifier_hard2, \"voting_classifier_hard_dataset2.pkl\")\n",
    "# Validera modellen på dataset 2\n",
    "ensemble.evaluate_voting_classifier(X_val2, y_val2)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
